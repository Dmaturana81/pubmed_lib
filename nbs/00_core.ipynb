{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Functionalities to search, and retrieve data from pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from Bio import Entrez\n",
    "import sys\n",
    "# from tinydb import TinyDB, Query, where\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from datetime import datetime, timedelta, date\n",
    "from collections import defaultdict, Counter\n",
    "import  pickle\n",
    "from fastcore.all import *\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from parse import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "load_dotenv('pass.env')\n",
    "email = os.environ.get('EMAIL')\n",
    "api_key = os.environ.get('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "regex = re.compile((\"([a-z0-9!#$%&'*+\\/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+\\/=?^_`\"\n",
    "                    \"{|}~-]+)*(@|\\sat\\s)(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?(\\.|\"\n",
    "                    \"\\sdot\\s))+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?)\"))\n",
    "reg_email = re.compile(\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\")\n",
    "db_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def searchpb(\n",
    "    search_term:str, #Query to be search in pubmed\n",
    "    retmax:int = 5000, #Maximum number of results to be retrieved\n",
    "    retmode:str ='xml', #Format of the returned data, options are xml, \n",
    "    sort:str='relevance', #Way to sort the results\n",
    "    mindate:int = None, #Initial data to be search from, year\n",
    "    maxdate:int = None #Final data to be search from, year\n",
    "    ):\n",
    "    \"\"\"\n",
    "    It receive a query to be searched in pubmed and return the handler of the search\n",
    "    \"\"\"\n",
    "    Entrez.email = email\n",
    "    Entrez.api_key = api_key\n",
    "    handle = Entrez.esearch(db='pubmed',\n",
    "                            sort=sort,\n",
    "                            retmax=retmax,\n",
    "                            retmode=retmode,\n",
    "                            term=search_term,\n",
    "                            mindate = mindate,\n",
    "                            maxdate = maxdate)\n",
    "    return Entrez.read(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fetch_details(\n",
    "    IdList:list #List of pubmedIDs to fetch the details\n",
    "    ):\n",
    "    \"\"\"\n",
    "    It receive a list of pubmedIds from a search, and retrieve all the details of those publications\n",
    "    \"\"\"\n",
    "    ids = ','.join(IdList)\n",
    "    Entrez.email = email\n",
    "    Entrez.api_key = api_key\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getParsedArticles(name, years = 3):\n",
    "    query = name + '[Author]'\n",
    "    results = searchpb(query, 100, maxdate = 2021, mindate = 2021 - years)\n",
    "    id_list = results['IdList']\n",
    "    if len(id_list) == 0:\n",
    "        return 0\n",
    "    papers = fetch_details(id_list)\n",
    "    n_papers = len(id_list)\n",
    "    print('checking in {} Articles'.format(n_papers))\n",
    "    articles=[]\n",
    "    for i, paperinfo in enumerate(papers['PubmedArticle']):\n",
    "        article = parse_paperinfo(paperinfo)\n",
    "        if int(article['published']) < 2020 - years:\n",
    "            # print('to old, article published on {}'.format(article['published']))\n",
    "            continue\n",
    "        articles.append(article)\n",
    "    print('Keeping with {} from last {} years'.format(len(articles), years))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getParsedArticlesPeriod(name, maxdate=2020, years = 3, top_n=None, verbose=False):\n",
    "    query = name + '[Author]'\n",
    "    results = searchpb(query, 1000, maxdate = maxdate, mindate = maxdate - years)\n",
    "    id_list = results['IdList']\n",
    "    if len(id_list) == 0:\n",
    "        return ([],0)\n",
    "    papers = fetch_details(id_list)\n",
    "    n_papers = len(id_list)\n",
    "    if verbose:\n",
    "        print('checking in {} Articles'.format(n_papers))\n",
    "    articles=[]\n",
    "    for i, paperinfo in enumerate(papers['PubmedArticle']):\n",
    "        article = parse_paperinfo(paperinfo)\n",
    "        if maxdate < int(article['published'])  or int(article['published']) < maxdate -years :\n",
    "            # print('to old, article published on {}'.format(article['published']))\n",
    "            continue\n",
    "        articles.append(article)\n",
    "    if len(articles) == 0:\n",
    "        if verbose:\n",
    "            print('No articles in the time period')\n",
    "        return ([],n_papers)\n",
    "    elif top_n:\n",
    "        df = pd.DataFrame(articles).sort_values('published', ascending=False)\n",
    "        df = df.iloc[:top_n]\n",
    "        articles = df.to_dict('records')\n",
    "    if verbose:\n",
    "        print('Keeping with {} from last {} years'.format(len(articles), years))\n",
    "    return (articles, n_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fetchPubmedArticles(name, start, end, path, db_path = '/Volumes/Users/matu/Documents/Xcode/SFDC/db.pckl'):\n",
    "    \"\"\"Function to search in pubmed by name, start and end year.\n",
    "    It checks first in the database of abstracts downloaded before.\n",
    "    Create a csv file with the parsed pubmed results including abstract, authors, etc. (look at pubmed_utils)\n",
    "\n",
    "    return (pd.Dataframe) -> the DataFrame with all the information retrieved\"\"\"\n",
    "    db = loadDB(db_path)\n",
    "    if name not in db:\n",
    "        print('adding new year {} for {}'.format(start, name))\n",
    "        (pubmedData, total) = getParsedArticlesPeriod(name, start, end)\n",
    "        if pubmedData == 0:\n",
    "            db.update({name: {str(start):[total, 0]}})\n",
    "            return \n",
    "        else:\n",
    "            db.update({name: {str(start):[total, len(pubmedData)]}})\n",
    "    else:\n",
    "        if (str(start) in db[name]) and (str(end) in db[name]):\n",
    "            print(f\"{name} already in DB with year {start} - {end}, passing\")\n",
    "            df = pd.read_csv('{}/{}_{}_{}.csv'.format(path, name, start, start - end))\n",
    "            return df\n",
    "        else:\n",
    "            (pubmedData, total) = getParsedArticlesPeriod(name, start, end)\n",
    "            if pubmedData == 0:\n",
    "                db[name].update({str(start):[total, 0]})\n",
    "                return \n",
    "            else:\n",
    "                db[name].update({str(start):[total, len(pubmedData)]})\n",
    "    df = pd.DataFrame(pubmedData)\n",
    "    file_output = '{}/{}_{}_{}.csv'.format(path, name, start, start - end)\n",
    "    df.to_csv(file_output)\n",
    "    saveDB(db, db_path)\n",
    "    if df.shape[0] >= 10:\n",
    "        df = df.sort_values('published', ascending=False)\n",
    "        print('Using the 10 newer papers')\n",
    "        return df.iloc[:10]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def retrieveArticles():\n",
    "    results = searchpb('Peter Ihnat[Author]')\n",
    "    papers = fetch_details(results['IdList'])\n",
    "    articles=[]\n",
    "    for i, paperinfo in enumerate(papers['PubmedArticle']):\n",
    "        article = parse_paperinfo(paperinfo)\n",
    "        articles.append(article)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
