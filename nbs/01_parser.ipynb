{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser\n",
    "\n",
    "> Functionalities to parse the different information comming from pubmed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from Bio import Entrez\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from datetime import datetime, timedelta, date\n",
    "from collections import defaultdict, Counter\n",
    "import  pickle\n",
    "from fastcore.all import *\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pubmed_lib.core import *\n",
    "from pubmed_lib.data import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "regex = re.compile((\"([a-z0-9!#$%&'*+\\/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+\\/=?^_`\"\n",
    "                    \"{|}~-]+)*(@|\\sat\\s)(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?(\\.|\"\n",
    "                    \"\\sdot\\s))+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?)\"))\n",
    "reg_email = re.compile(\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\")\n",
    "db_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parsePubmedData(pubmeddata):\n",
    "    \"\"\"\n",
    "    Receive the xml section of PubmedData and return list of ids\n",
    "    :param pubmeddata:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # accepted = {x.attributes['PubStatus']: x['Year'] for x in pubmeddata['History']}\n",
    "    # print(accepted)\n",
    "    ids = {x.attributes['IdType']: str(x) for x in pubmeddata['ArticleIdList']}\n",
    "    # print(ids)\n",
    "    # accepted.update(ids)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parseArticle(article_info):\n",
    "    \"\"\"\n",
    "\n",
    "    :param article_info: dictionary from key Article of an Medline citation\n",
    "    :return (dict): tuple of dictionary with information from paper and autors\n",
    "    \"\"\"\n",
    "    # Extract information about paper content\n",
    "    title = article_info['ArticleTitle']\n",
    "    journal = article_info['Journal']['Title']\n",
    "    published_date = article_info['Journal']['JournalIssue']['PubDate']\n",
    "    if 'Year' in published_date:\n",
    "        published = published_date['Year']\n",
    "    elif 'MedlineDate' in published_date:\n",
    "        try:\n",
    "            published = re.findall(r'\\d\\d\\d\\d',published_date['MedlineDate'])[0]\n",
    "        except:\n",
    "            published = published_date['MedlineDate'][:4]\n",
    "    try:\n",
    "#         print(article_info)\n",
    "        abstract = '. '.join(article_info['Abstract']['AbstractText'])\n",
    "    except:\n",
    "        abstract = ''\n",
    "    try:\n",
    "        autorlist = article_info['AuthorList']\n",
    "    except:\n",
    "        print('no autors found, jumping next')\n",
    "        autorlist = []\n",
    "    return {'abstract': abstract, 'autorlist': autorlist, 'title': title, 'journal': journal,\n",
    "            'published':published}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_email(affil_text):\n",
    "\n",
    "    \"\"\"\n",
    "    Find email from given string\n",
    "    :param affil_text:\n",
    "    :return str:\n",
    "    \"\"\"\n",
    "    match = re.search(r'[\\w.-]+@[\\w.-]+', affil_text)\n",
    "    if match is not None:\n",
    "        email = match.group()\n",
    "        email = email.strip('.;,')\n",
    "    else:\n",
    "        email = ''\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parseMayorKeys(citationInfo):\n",
    "    keywordList = citationInfo['KeywordList']\n",
    "    \n",
    "    if len(keywordList) == 0:\n",
    "        (mayorMesh, minorMesh) = parseMeshKeys(citationInfo)\n",
    "        mayorMesh.extend(minorMesh)\n",
    "        keys = mayorMesh\n",
    "    else:\n",
    "        keys = [str(x) for x in keywordList[0] if x.attributes['MajorTopicYN'] == 'Y']\n",
    "        # keys.extend(mayorMesh)\n",
    "        # keys.extend(minorMesh)\n",
    "    return keys\n",
    "\n",
    "# def parseMayorKeys(citationInfo):\n",
    "#     keywordList = citationInfo['KeywordList']\n",
    "#     if len(keywordList) == 0:\n",
    "#         return []\n",
    "#     else:\n",
    "#         return [str(x) for x in keywordList[0] if x.attributes['MajorTopicYN'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parseMeshKeys(citationInfo):\n",
    "    if 'MeshHeadingList' not in citationInfo.keys():\n",
    "        return [], []\n",
    "    meshKeys = citationInfo['MeshHeadingList']\n",
    "    mayorkeys = [str(x['DescriptorName']) for x in meshKeys if x['DescriptorName'].attributes['MajorTopicYN']=='Y']\n",
    "    minorKeys = [str(x['DescriptorName']) for x in meshKeys if x['DescriptorName'].attributes['MajorTopicYN']=='N']\n",
    "    for x in [mayorkeys, minorKeys]:\n",
    "        if x is None:\n",
    "            x = []\n",
    "    return mayorkeys, minorKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# def parseMeshKeys(citationInfo):\n",
    "#     if 'MeshHeadingList' not in citationInfo.keys():\n",
    "#         return [], []\n",
    "#     meshKeys = citationInfo['MeshHeadingList']\n",
    "#     mayorkeys = [str(x['DescriptorName']) for x in meshKeys if x['DescriptorName'].attributes['MajorTopicYN']=='Y']\n",
    "#     minorKeys = [str(x['DescriptorName']) for x in meshKeys if x['DescriptorName'].attributes['MajorTopicYN']=='N']\n",
    "#     return mayorkeys, minorKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parseKeys(citationInfo):\n",
    "    return parseMayorKeys(citationInfo), parseMeshKeys(citationInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = searchpb('Daniel Maturana', email=email, api_key=api_key)\n",
    "pubs = fetch_details(res['IdList'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParsedArticles(name, years = 3):\n",
    "    query = name + '[Author]'\n",
    "    results = searchpb(query, 100, maxdate = 2021, mindate = 2021 - years)\n",
    "    id_list = results['IdList']\n",
    "    if len(id_list) == 0:\n",
    "        return 0\n",
    "    papers = fetch_details(id_list)\n",
    "    n_papers = len(id_list)\n",
    "    print('checking in {} Articles'.format(n_papers))\n",
    "    articles=[]\n",
    "    for i, paperinfo in enumerate(papers['PubmedArticle']):\n",
    "        article = parse_paperinfo(paperinfo)\n",
    "        if int(article['published']) < 2020 - years:\n",
    "            # print('to old, article published on {}'.format(article['published']))\n",
    "            continue\n",
    "        articles.append(article)\n",
    "    print('Keeping with {} from last {} years'.format(len(articles), years))\n",
    "    return articles\n",
    "\n",
    "def getParsedArticlesPeriod(name, maxdate=2020, years = 3, top_n=None, verbose=False):\n",
    "    query = name + '[Author]'\n",
    "    results = searchpb(query, 1000, maxdate = maxdate, mindate = maxdate - years)\n",
    "    id_list = results['IdList']\n",
    "    if len(id_list) == 0:\n",
    "        return ([],0)\n",
    "    papers = fetch_details(id_list)\n",
    "    n_papers = len(id_list)\n",
    "    if verbose:\n",
    "        print('checking in {} Articles'.format(n_papers))\n",
    "    articles=[]\n",
    "    for i, paperinfo in enumerate(papers['PubmedArticle']):\n",
    "        article = parse_paperinfo(paperinfo)\n",
    "        if maxdate < int(article['published'])  or int(article['published']) < maxdate -years :\n",
    "            # print('to old, article published on {}'.format(article['published']))\n",
    "            continue\n",
    "        articles.append(article)\n",
    "    if len(articles) == 0:\n",
    "        if verbose:\n",
    "            print('No articles in the time period')\n",
    "        return ([],n_papers)\n",
    "    elif top_n:\n",
    "        df = pd.DataFrame(articles).sort_values('published', ascending=False)\n",
    "        df = df.iloc[:top_n]\n",
    "        articles = df.to_dict('records')\n",
    "    if verbose:\n",
    "        print('Keeping with {} from last {} years'.format(len(articles), years))\n",
    "    return (articles, n_papers)\n",
    "\n",
    "\n",
    "def fetchPubmedArticles(name, start, end, path, db_path = '/Volumes/Users/matu/Documents/Xcode/SFDC/db.pckl'):\n",
    "    \"\"\"Function to search in pubmed by name, start and end year.\n",
    "    It checks first in the database of abstracts downloaded before.\n",
    "    Create a csv file with the parsed pubmed results including abstract, authors, etc. (look at pubmed_utils)\n",
    "\n",
    "    return (pd.Dataframe) -> the DataFrame with all the information retrieved\"\"\"\n",
    "    db = loadDB(db_path)\n",
    "    if name not in db:\n",
    "        print('adding new year {} for {}'.format(start, name))\n",
    "        (pubmedData, total) = getParsedArticlesPeriod(name, start, end)\n",
    "        if pubmedData == 0:\n",
    "            db.update({name: {str(start):[total, 0]}})\n",
    "            return \n",
    "        else:\n",
    "            db.update({name: {str(start):[total, len(pubmedData)]}})\n",
    "    else:\n",
    "        if (str(start) in db[name]) and (str(end) in db[name]):\n",
    "            print(f\"{name} already in DB with year {start} - {end}, passing\")\n",
    "            df = pd.read_csv('{}/{}_{}_{}.csv'.format(path, name, start, start - end))\n",
    "            return df\n",
    "        else:\n",
    "            (pubmedData, total) = getParsedArticlesPeriod(name, start, end)\n",
    "            if pubmedData == 0:\n",
    "                db[name].update({str(start):[total, 0]})\n",
    "                return \n",
    "            else:\n",
    "                db[name].update({str(start):[total, len(pubmedData)]})\n",
    "    df = pd.DataFrame(pubmedData)\n",
    "    file_output = '{}/{}_{}_{}.csv'.format(path, name, start, start - end)\n",
    "    df.to_csv(file_output)\n",
    "    saveDB(db, db_path)\n",
    "    if df.shape[0] >= 10:\n",
    "        df = df.sort_values('published', ascending=False)\n",
    "        print('Using the 10 newer papers')\n",
    "        return df.iloc[:10]\n",
    "    return df\n",
    "\n",
    "def retrieveArticles():\n",
    "    results = searchpb('Peter Ihnat[Author]')\n",
    "    papers = fetch_details(results['IdList'])\n",
    "    articles=[]\n",
    "    for i, paperinfo in enumerate(papers['PubmedArticle']):\n",
    "        article = parse_paperinfo(paperinfo)\n",
    "        articles.append(article)\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def parse_paperinfo(\n",
    "    paperinfo_xml:str #Information \n",
    "    ):\n",
    "    \"\"\"\n",
    "    :param paperinfo_xml:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    PubmedData = parsePubmedData(paperinfo_xml['PubmedData'])\n",
    "    article_xml = parseArticle(paperinfo_xml['MedlineCitation']['Article'])\n",
    "    mayorKeys, (mayorMeshKeys, minorMeshKeys) = parseKeys(paperinfo_xml['MedlineCitation'])\n",
    "    article_xml['mayorKeys'] = mayorKeys\n",
    "    article_xml['mayorMesh'] = mayorMeshKeys\n",
    "    article_xml['minorMesh'] = minorMeshKeys\n",
    "    try:\n",
    "        autorlist = []\n",
    "        for author_xml in article_xml['autorlist']:\n",
    "            if author_xml.attributes['ValidYN'] == 'N':\n",
    "                continue\n",
    "            autor_dict = parse_author_xml(author_xml)\n",
    "            if autor_dict is None:\n",
    "                continue\n",
    "            autorlist.append(autor_dict)\n",
    "            # article_xml['autorlist'][i] = autor_dict\n",
    "    except:\n",
    "        print('ERROR: parsing author {}'.format(author_xml))\n",
    "    finally:\n",
    "        article_xml['autorlist'] = autorlist\n",
    "        PubmedData.update(article_xml)\n",
    "    return PubmedData\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_author_xml(autor_xml):\n",
    "    \"\"\"\n",
    "    (dict)->dict\n",
    "    Receive un diccionario con las informaciones de autor proveniente de pubmed xml article\n",
    "\n",
    "    :param autor_xml:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Return false if no author information found\n",
    "    if 'CollectiveName' in autor_xml:\n",
    "        return\n",
    "    # try to parse information from XML\n",
    "    try:\n",
    "        #get Identifier (only orcid is used now so if they have identifier it should be the first value\n",
    "        if len(autor_xml['Identifier']) > 0:\n",
    "            autorID = autor_xml['Identifier'][0]\n",
    "        else:\n",
    "            autorID = ''\n",
    "        #Get the affilaition details from that author, if he had\n",
    "        if len(autor_xml['AffiliationInfo']) > 0:\n",
    "            AFFs = ';'.join([affiliationinfo['Affiliation'] for affiliationinfo in autor_xml['AffiliationInfo']])\n",
    "        else:\n",
    "            AFFs = ''\n",
    "        #Retrieving the name information, it is a must and should exist\n",
    "        autorFN = autor_xml['ForeName']\n",
    "        autorLN = autor_xml['LastName']\n",
    "        autorIN = autor_xml['Initials']\n",
    "        name = autorFN + ' ' + autorLN\n",
    "        #Start parsing or retrieving information for country, email, company, institute from affiliation\n",
    "        country_name, state = find_country(AFFs)\n",
    "        emails = parse_email(AFFs)\n",
    "        data = {'Fname': autorFN, 'Lname': autorLN, 'emails': emails, 'affiliations': AFFs, 'countries': country_name,\n",
    "                'identifier': autorID, 'name': name, 'n_papers': 0, 'updated': date.today().strftime('%d-%m-%Y'),\n",
    "                'state': state, 'initials': autorIN}\n",
    "        return data\n",
    "\n",
    "    except ValueError:\n",
    "        print('not possible to get info value error')\n",
    "        return\n",
    "    except OSError as err:\n",
    "        print(\"OS Error: {0}\".format(err))\n",
    "        return\n",
    "    except:\n",
    "        print('error en parsing')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_country(location):\n",
    "    \"\"\"\n",
    "    Find country from string\n",
    "    \"\"\"\n",
    "    if len(location) == 0:\n",
    "        return '', ''\n",
    "    location_lower = location.lower()\n",
    "    for country in COUNTRY:\n",
    "        for c in country:\n",
    "            if c in location_lower:\n",
    "                if country[0] == 'brazil':\n",
    "                    state = find_state(location)\n",
    "                else:\n",
    "                    state = ''\n",
    "                return country[0], state\n",
    "    return '', ''\n",
    "\n",
    "def find_state(location):\n",
    "    \"\"\"\n",
    "    (str)->str\n",
    "    Find state of Brazl from the affiliation details\n",
    "    :param location:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    location_lower = location\n",
    "    for state in BR_STATES:\n",
    "        if state in location_lower:\n",
    "                return state.lstrip(' ')\n",
    "    return ''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
